\documentclass[11pt,a4paper,twoside]{thesis}

\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage[left=3cm,right=3cm,bottom=3.5cm,top=3.5cm]{geometry}
\usepackage{titlesec}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}
\usepackage{booktabs}

\begin{document}

%%%% CARATULA

\def\autor{Adrian Norberto Marino}
\def\tituloTesis{Chatbot para recomendacion personalizada de contenido}
\def\runtitulo{Resumen}
\def\runtitle{Chatbot para recomendacion personalizada de contenido}
\def\director{Roberto Abalde}

\def\lugar{Buenos Aires, Argentina, 2024}

% -----------------------------------------------------------------------------
% Caratula,  Resumen, agradecimientos y dedicatoria.
% -----------------------------------------------------------------------------
\input{cover.tex}
%
\frontmatter
\pagestyle{empty}
\input{abstract.tex}
%
%\cleardoublepage
%\input{thanks.tex} % OPCIONAL: comentar si no se quiere
%
\cleardoublepage
\input{dedication.tex}  % OPCIONAL: comentar si no se quiere
% -----------------------------------------------------------------------------
%
%
%
%\cleardoublepage
\tableofcontents
%
%
\mainmatter
\pagestyle{headings}
%
%
%
%
% -----------------------------------------------------------------------------
% Contenido de la tesis
% -----------------------------------------------------------------------------

\setitemize{itemsep=0.5pt}

\chapter{Introducción}

Como repaso, este trabajo esta basado o inspirado en los iguientes
trabajos previos:

\begin{itemize}
    \item \href{https://arxiv.org/abs/2303.14524}{Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System (principalmente)} ~\cite{chatrec}
\end{itemize}

La principal diferencia radica en utilizar un LLM que corre localmente
en vez de un servicio en la nube, como sucede con el API de Open AI o Anthopic, donde
se accede a un modelo de grandes dimensiones(cantidad de pesos) pero a un costo
elevado para la cantidad de request que fue necesario realizar tanto par el
desarrollo como la evaluación de los modelos abordados en este trabajo.

Como modelo local se opto por utilizar la plataforma Ollama. esta permite descargar modelos similares a

Ademas de utilizar un LLM como


\chapter{Modelos}

\chapter{Resultados}


\section{Subsection}

\chapter{Conclusiones}

\section{Subsection}

%%%% BIBLIOGRAFÍA

% Establece el estilo de las referencias bibliográficas
% otago, plain, apa, ieee, IEEEtran, etc...
\bibliographystyle{IEEEtran}

\renewcommand{\bibname}{Referencias}
\bibliography{cites} % Especifica el nombre del archivo .bib sin la extensión .bib
\end{document}