{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0417277b-47df-4113-a7b3-8f960db06f1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelos: Text LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef46fb7-b5c8-47e8-b90a-99a1c3027f4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Papers\n",
    "\n",
    "* [Chat-REC: Towards Interactive and Explainable\n",
    "LLMs-Augmented Recommender System](https://github.com/adrianmarino/thesis-paper/blob/master/docs/ideas/2303.14524.pdf)\n",
    "* [Large Language Models as Zero-Shot Conversational\n",
    "Recommenders](https://github.com/adrianmarino/thesis-paper/blob/master/docs/ideas/3583780.3614949.pdf)\n",
    "* [Large Language Models are Competitive Near Cold-start\n",
    "Recommenders for Language- and Item-based Preferences](https://github.com/adrianmarino/thesis-paper/blob/master/docs/ideas/3604915.3608845.pdf)\n",
    "\n",
    "### Implementation\n",
    "\n",
    "* [Langchain Quickstart](https://python.langchain.com/docs/integrations/llms/ollama)\n",
    "* [Langchain Ollama](https://python.langchain.com/docs/integrations/llms/ollama)\n",
    "* [Langchain Agents](https://python.langchain.com/docs/modules/agents/)\n",
    "* [Ollama Model File](https://github.com/jmorganca/ollama/blob/main/docs/modelfile.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e430dd-e279-4258-82a4-6b7a1347304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834b2f2d-4103-4cf5-880d-10404d8ec7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH             = '../../..'\n",
    "LIB_PATH              = f'{BASE_PATH}/lib'\n",
    "DATASET_PATH          = f'{BASE_PATH}/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98e7bf4-f41a-43f6-b7b7-a991d00f82de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 16:07:14.723569: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-13 16:07:15.131556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-13 16:07:15.509465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-13 16:07:15.523363: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(LIB_PATH)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import util as ut\n",
    "\n",
    "import recommender as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b2aa52-be91-4ff8-b9d6-52b525bec2ca",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "361db57b-e209-46a2-83cd-011a6e46f9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat_model = ChatOllama(\n",
    "    model=\"llama2:7b-chat\",\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    ")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You a a common cahtbot'),\n",
    "    MessagesPlaceholder(variable_name='history'),\n",
    "    ('human', '{request}')\n",
    "])\n",
    "\n",
    "\n",
    "chain = template | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0c8f21a-e555-4201-bf9d-6928f8cc0c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You a a common cahtbot'), AIMessage(content='hola'), HumanMessage(content='hola como estas'), HumanMessage(content='Tell me about the history of AI')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.invoke(\n",
    "    {\n",
    "        'request': 'Tell me about the history of AI',\n",
    "        'history': [\n",
    "            AIMessage(content='hola'),\n",
    "            HumanMessage(content='hola como estas')\n",
    "        ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a0a60-26ff-49de-8915-2579a495fa51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
