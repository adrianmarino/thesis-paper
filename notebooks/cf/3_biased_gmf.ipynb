{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0417277b-47df-4113-a7b3-8f960db06f1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Models: Biased Generalized Matrix Factorization (Biased-GMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dde5e70-5b86-460f-8791-20fcb554c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "BASE_PATH='../..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98e7bf4-f41a-43f6-b7b7-a991d00f82de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/adrian/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(f'{BASE_PATH}/lib')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bunch import Bunch\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import SparseAdam, Adam\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pytorch_common.util as pu\n",
    "from pytorch_common.modules.fn import Fn\n",
    "from pytorch_common.callbacks import EarlyStop, \\\n",
    "                                     ReduceLROnPlateau, \\\n",
    "                                     Validation, \\\n",
    "                                     SaveBestModel\n",
    "from pytorch_common.callbacks.output import Logger, \\\n",
    "                                            MetricsPlotter\n",
    "\n",
    "from pytorch_common.util import set_device_name, \\\n",
    "                                get_device, \\\n",
    "                                LoggerBuilder\n",
    "\n",
    "import model as ml\n",
    "import data.dataset as ds\n",
    "\n",
    "import metric as mt\n",
    "import metric.discretizer as dr\n",
    "\n",
    "import data.plot as pl\n",
    "import data as dt\n",
    "\n",
    "import logging\n",
    "import random\n",
    "\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1da33-a8da-47c9-b174-0b0885b05b50",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60a3838-9787-411d-b9f1-8a942321cbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">RootLogger</span><span style=\"color: #000000; text-decoration-color: #000000\"> root </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">INFO</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mRootLogger\u001b[0m\u001b[39m root \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mINFO\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pu.LoggerBuilder().on_console().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd7574f-043a-4fc3-8ab8-bfd55b6a92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu.set_device_name('gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad1a1e0-b35e-4b40-ab06-beae8fbb244a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">device</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mdevice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'cuda'\u001b[0m, \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pu.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f956317d-0e48-4518-a219-51700d272b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ba7b0b-b5d8-47ec-8995-642b7b21e6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21fa4041-5682-4332-b139-6aca63d05ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'1.11.0'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'1.11.0'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5fb890c-e080-4efc-9fc1-08921ae2465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(value):\n",
    "    random.seed(value)\n",
    "    np.random.seed(value)\n",
    "    torch.manual_seed(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f9d948-5300-4141-8fbc-4423669b2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8334d07-f306-42b4-8ea1-cc27b82eb343",
   "metadata": {},
   "source": [
    "## Carga de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34c660c-4802-498a-81b7-07bed14de07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 153892 entries, 0 to 153891\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   user_id                      153892 non-null  int64         \n",
      " 1   user_seq                     153892 non-null  int64         \n",
      " 2   user_movie_tags              153892 non-null  object        \n",
      " 3   user_movie_rating            153892 non-null  int64         \n",
      " 4   user_movie_rating_timestamp  153892 non-null  datetime64[ns]\n",
      " 5   user_movie_rating_year       153892 non-null  int64         \n",
      " 6   movie_id                     153892 non-null  int64         \n",
      " 7   movie_seq                    153892 non-null  int64         \n",
      " 8   movie_title                  153892 non-null  string        \n",
      " 9   movie_genres                 153892 non-null  object        \n",
      " 10  movie_for_adults             153892 non-null  bool          \n",
      " 11  movie_original_language      153892 non-null  string        \n",
      " 12  movie_overview               153892 non-null  string        \n",
      " 13  movie_tags                   153892 non-null  object        \n",
      " 14  movie_release_year           153892 non-null  int64         \n",
      " 15  movie_imdb_id                153892 non-null  int64         \n",
      "dtypes: bool(1), datetime64[ns](1), int64(8), object(3), string(3)\n",
      "memory usage: 18.9+ MB\n"
     ]
    }
   ],
   "source": [
    "def to_tensor(obs, device, columns): \n",
    "    data = obs[columns]\n",
    "    if type(data) == pd.DataFrame:\n",
    "        data = data.values\n",
    "    return torch.tensor(data).to(device)\n",
    "\n",
    "features_fn = lambda obs, device: to_tensor(obs, device, ['user_seq', 'movie_seq'])\n",
    "target_fn   = lambda obs, device: to_tensor(obs, device, ['user_movie_rating'])\n",
    "\n",
    "dataset = ds.MovieLensTMDBDatasetFactory.from_path(\n",
    "    path             = f'{BASE_PATH}/datasets',\n",
    "    transform        = features_fn,\n",
    "    target_transform = target_fn,\n",
    "    device           = cpu,\n",
    "    filter_fn        = lambda df: df[(df['user_movie_rating_year'] >= 2005) & (df['user_movie_rating_year'] <= 2019)]\n",
    ")\n",
    "dataset.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d53ab348-74a1-454e-8efc-01b0ecf8c640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 18:24:49,946 - INFO - Train: 82.85 % - Test: 8.97 %\n"
     ]
    }
   ],
   "source": [
    "train_set, eval_set = dataset.split_train_eval(split_year=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ebd42-69d1-4c70-86bd-21fdf655ea17",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definicion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562a42f0-ed70-4723-b136-fbd3a3e6c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Bunch({\n",
    "    'lr': 0.001,\n",
    "    'lr_factor': 0.1,\n",
    "    'lr_patience': 3,\n",
    "    'epochs': 50,\n",
    "    'embedding_size': 50,\n",
    "    'n_workers': 24,\n",
    "    'batch_size': 64,\n",
    "    'n_users': len(dataset.features_uniques[0]),\n",
    "    'n_items': len(dataset.features_uniques[1]),\n",
    "    'device': get_device()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78291b6-de95-42d9-accb-eaeb0b223979",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_set, params.batch_size, num_workers=params.n_workers, pin_memory=True)\n",
    "test_dl  = DataLoader(eval_set,  params.batch_size, num_workers=params.n_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "955b0576-fde1-4b08-ace2-7ea873d3e45c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBiasedGMF\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_users\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_users\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_items\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_size\u001b[49m\n\u001b[0;32m----> 5\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# make_dot(y_pred, params=dict(model.named_parameters()))\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ml.BiasedGMF(\n",
    "    n_users        = params.n_users,\n",
    "    n_items        = params.n_items,\n",
    "    embedding_size = params.embedding_size\n",
    ").to(params.device)\n",
    "model\n",
    "# make_dot(y_pred, params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2455c3-91ff-4b28-934a-623193c38674",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d5198-fa03-4129-ba90-1346838b1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(\n",
    "    train_dl,\n",
    "    epochs      = params.epochs,\n",
    "    loss_fn     = ml.MSELossFn(),\n",
    "    optimizer   = Adam(\n",
    "        params       = model.parameters(),\n",
    "        lr           = params.lr\n",
    "    ),\n",
    "    callbacks   = [\n",
    "        Validation(\n",
    "            test_dl,\n",
    "            metrics = { 'val_loss': ml.MSELossFn(float_result=True)},\n",
    "            each_n_epochs=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(metric='val_loss', mode='min', factor=params.lr_factor, patience=params.lr_patience),\n",
    "        MetricsPlotter(metrics=['train_loss', 'val_loss'], plot_each_n_epochs=2),\n",
    "        Logger(['time', 'epoch', 'train_loss', 'val_loss', 'patience', 'lr']),\n",
    "        SaveBestModel(metric='val_loss', path='../weights', experiment_name='gfm_bias')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768ec4b-b787-4fe5-832a-235bb4959daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f'{BASE_PATH}/weights/2022-07-23_16-23-41--gfm_bias--epoch_21--val_loss_0.9372825026512146.pt'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "deep_fm_predictor = ml.ModulePredictor(model)\n",
    "\n",
    "validator = ml.Validator(\n",
    "    n_samples  = 500,\n",
    "    batch_size = 10000,\n",
    "    metrics    = [\n",
    "        mt.RMSE(),\n",
    "\n",
    "        mt.MeanAveragePrecisionAtk(user_index=0, k=5, discretizer=dr.between(4, 5)),\n",
    "        mt.MeanUserFBetaScoreAtk(user_index=0, k=5, discretizer=dr.between(4, 5)),\n",
    "        mt.MeanUserPrecisionAtk(user_index=0, k=5, discretizer=dr.between(4, 5)),\n",
    "        mt.MeanUserRecallAtk(user_index=0, k=5, discretizer=dr.between(4, 5)),\n",
    "        \n",
    "        mt.MeanAveragePrecisionAtk(user_index=0, k=5, discretizer=dr.between(3, 5)),\n",
    "        mt.MeanUserFBetaScoreAtk(user_index=0, k=5, discretizer=dr.between(3, 5)),\n",
    "        mt.MeanUserPrecisionAtk(user_index=0, k=5, discretizer=dr.between(3, 5)),\n",
    "        mt.MeanUserRecallAtk(user_index=0, k=5, discretizer=dr.between(3, 5))\n",
    "    ],\n",
    "    predictors = [deep_fm_predictor]\n",
    ")\n",
    "\n",
    "summary = validator.validate(eval_set)\n",
    "summary.save(f'{BASE_PATH}/metrics/biased_gmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28861c8-9dbf-4bcf-ab4b-1b96ee089def",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = ml.ValidatorSummary.load(f'{BASE_PATH}/metrics/biased_gmf')\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d37c3-d82b-437a-a496-6438342934e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.plot(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274d054-daed-4742-b93f-1445e1f985a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
